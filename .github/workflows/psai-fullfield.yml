name: PSAI Full-Field Daily

on:
  schedule:
    - cron: '15 13 * * *'  # 09:15 ET daily
  workflow_dispatch:
  push:
    paths:
      - 'data/**'
      - 'scripts/**'
      - 'public/*.html'
      - '.github/workflows/psai-fullfield.yml'

permissions:
  contents: write
  issues: write

concurrency:
  group: psai-fullfield
  cancel-in-progress: false

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Initialize data files from seeds
        run: |
          if [ ! -f data/tools.csv ]; then cp data/init_tools.csv data/tools.csv; fi
          if [ ! -f data/sources.csv ]; then cp data/init_sources.csv data/sources.csv; fi
          if [ ! -f data/filters.csv ]; then cp data/init_filters.csv data/filters.csv; fi

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install PyYAML beautifulsoup4 feedgen requests

      # 1) Discovery → candidates.json (lightweight; DeepSweep does a wider pass)
      - name: Discovery (new tools)
        run: |
          python scripts/discover.py --light --out data/candidates.json
          python scripts/merge_candidates.py --candidates data/candidates.json --tracker data/tools.csv --out data/tools.csv

      # 2) Harvest releases/changelogs → news_log.json (trim to 30d)
      - name: Harvest → Log (30d)
        run: python scripts/harvest.py --tools data/tools.csv --sources data/sources.csv --log data/news_log.json

      # 3) Update tracker "Updates/Status" column inline
      - name: Update tracker status
        run: python scripts/update_tracker.py --tracker data/tools.csv --log data/news_log.json --out data/tools.csv

      # 4) Re-scan existing tool websites for new tools
      - name: Re-scan tool websites
        run: python scripts/rescan_sites.py

      # 5) Build feeds (JSON Feed + RSS) and inject Sources link
      - name: Build feeds
        env:
          SITE_URL: ${{ vars.SITE_URL }}
        run: |
          SITE="${SITE_URL}"
          if [ -z "$SITE" ]; then
            SITE="https://${GITHUB_REPOSITORY_OWNER}.github.io/${GITHUB_REPOSITORY#*/}"
          fi
          python scripts/build_feed_from_log.py --site "$SITE"

      # 6) Build sources listing pages (cards + table) from CSV; auto-inject link to index.html
      - name: Build sources pages (cards + table)
        env:
          PSAI_INCLUDE_REGEX: "(agent|agentic|orchestr|mcp|ide|editor|review|code\\s*assistant)"
          PSAI_EXCLUDE_REGEX: "^(product\\s*hunt|reddit|hacker\\s*news|hn\\s*—|hn\\s*show|latentspace|ben['’]s\\s*bites|npm|pypi|docker\\s*hub)\\b"
          PSAI_MIN_STARS: "50"
        run: python scripts/build_sources_pages.py

      - name: Verify generated files
        run: ls -l public/

      # 7) Alert if ≥3 Major/Security items in last 24h (email + GH issue)
      - name: Alert on 3+ Major/Security in 24h
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SMTP_SERVER: ${{ secrets.SMTP_SERVER }}
          SMTP_PORT: ${{ secrets.SMTP_PORT }}
          SMTP_USERNAME: ${{ secrets.SMTP_USERNAME }}
          SMTP_PASSWORD: ${{ secrets.SMTP_PASSWORD }}
          MAIL_TO: ${{ secrets.MAIL_TO }}
          MAIL_FROM: ${{ secrets.MAIL_FROM }}
        run: |
          python - <<'PY'
          import json, datetime, os, smtplib
          from email.mime.text import MIMEText
          now = datetime.datetime.utcnow()
          cut = (now - datetime.timedelta(hours=24)).date().isoformat()
          data = json.load(open("data/news_log.json","r",encoding="utf-8"))
          hits = [i for i in data.get("items",[]) if i.get("date","") >= cut and i.get("severity","") in ("Major","Security")]
          if len(hits) >= 3:
              body = "\n".join(f"[{x['date']}] {x['tool']} — {x['headline']}" for x in hits)
              if all(os.getenv(k) for k in ["SMTP_SERVER","SMTP_PORT","SMTP_USERNAME","SMTP_PASSWORD","MAIL_TO","MAIL_FROM"]):
                  msg = MIMEText(body)
                  msg["Subject"] = "PSAI Alert: 3+ Major/Security updates"
                  msg["From"] = os.getenv("MAIL_FROM")
                  msg["To"] = os.getenv("MAIL_TO")
                  with smtplib.SMTP(os.getenv("SMTP_SERVER"), int(os.getenv("SMTP_PORT"))) as s:
                      s.starttls()
                      s.login(os.getenv("SMTP_USERNAME"), os.getenv("SMTP_PASSWORD"))
                      s.sendmail(os.getenv("MAIL_FROM"), [os.getenv("MAIL_TO")], msg.as_string())
              open("ALERT_LAST24.txt","w",encoding="utf-8").write(body)
          PY
          if [ -f ALERT_LAST24.txt ]; then
            gh issue create --title "PSAI Alert: $(date -u +%F) — 3+ Major/Security updates" --body "$(cat ALERT_LAST24.txt)" || true
          fi

      # 8) Commit changes (CSV, JSON, YAML, feeds, pages)
      - name: Commit changes
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/*.json data/*.csv data/*.yaml public/*.json public/*.xml public/*.html || true
          git commit -m "PSAI: full-field daily $(date -u +'%Y-%m-%dT%H:%M:%SZ')" || echo "Nothing to commit."
          git push || true
